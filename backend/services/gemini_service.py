import os
import logging
from typing import Dict, Any, Optional

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

logger = logging.getLogger(__name__)

class GeminiService:
    """Service pour la g√©n√©ration de contenu avec Google Gemini AI"""
    
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        
        if not self.api_key:
            logger.warning("GEMINI_API_KEY non trouv√©e, mode simulation activ√©")
            self.simulation_mode = True
        elif not GEMINI_AVAILABLE:
            logger.warning("google-generativeai non install√©, mode simulation activ√©")
            self.simulation_mode = True
        else:
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel("gemini-1.5-pro")
                self.simulation_mode = False
                logger.info("‚úÖ Gemini AI initialis√© avec succ√®s")
            except Exception as e:
                logger.error(f"‚ùå Erreur initialisation Gemini: {e}")
                self.simulation_mode = True
    
    def generate_linkedin_post(
        self, 
        prompt: str, 
        tone: str = "professionnel", 
        industry: str = "general",
        user_context: dict = None,
        article_context: dict = None
    ) -> str:
        """
        G√©n√©rer un post LinkedIn optimis√©
        
        Args:
            prompt: Le sujet/prompt du post
            tone: Le ton souhait√©
            industry: Le secteur d'activit√©
            user_context: Contexte utilisateur (nom, titre, etc.)
            article_context: Article source si applicable
            
        Returns:
            str: Le post g√©n√©r√©
        """
        if self.simulation_mode:
            return self._simulate_linkedin_generation(prompt, tone, industry, user_context, article_context)
        
        try:
            linkedin_prompt = self._build_linkedin_prompt(prompt, tone, industry, user_context, article_context)
            response = self.model.generate_content(linkedin_prompt)
            return response.text.strip()
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration Gemini: {str(e)}")
            return self._simulate_linkedin_generation(prompt, tone, industry, user_context, article_context)
    
    def _build_linkedin_prompt(
        self, 
        prompt: str, 
        tone: str, 
        industry: str,
        user_context: dict = None,
        article_context: dict = None
    ) -> str:
        """Construire le prompt optimis√© pour LinkedIn"""
        
        # Instructions de ton
        tone_instructions = {
            "professionnel": {
                "style": "Adoptez un ton professionnel et expert, utilisez un vocabulaire pr√©cis et cr√©dible",
                "voice": "Position d'autorit√© dans votre domaine",
                "approach": "Analytique et factuel avec des insights pratiques"
            },
            "inspirant": {
                "style": "Soyez motivant et positif, encouragez l'action et le d√©passement",
                "voice": "Leader visionnaire qui inspire",
                "approach": "Optimiste avec une vision d'avenir"
            },
            "familier": {
                "style": "Utilisez un ton conversationnel et accessible, comme une discussion entre coll√®gues",
                "voice": "Approchable et authentique",
                "approach": "Personnel et relatable"
            },
            "expert": {
                "style": "D√©montrez votre expertise technique avec des d√©tails pr√©cis",
                "voice": "Autorit√© reconnue dans le domaine",
                "approach": "Technique mais accessible"
            },
            "storytelling": {
                "style": "Racontez une histoire engageante avec des √©l√©ments narratifs",
                "voice": "Narrateur captivant",
                "approach": "√âmotionnel et m√©morable"
            }
        }
        
        tone_config = tone_instructions.get(tone, tone_instructions["professionnel"])
        
        # Contexte utilisateur
        user_info = ""
        if user_context:
            user_info = f"""
Contexte utilisateur:
- Nom: {user_context.get('name', 'Professionnel')}
- Secteur: {industry}
- Titre: {user_context.get('headline', f'Expert en {industry}')}
"""
        
        # Contexte article
        article_info = ""
        if article_context:
            article_info = f"""
Article source:
- Titre: {article_context.get('title', '')}
- Description: {article_context.get('description', '')}
- Source: {article_context.get('source', {}).get('name', '')}

Instructions: Cr√©ez un post qui commente cet article avec votre expertise personnelle.
"""
        
        # Prompt principal
        main_prompt = f"""
Vous √™tes un expert en cr√©ation de contenu LinkedIn. Cr√©ez un post viral et engageant.

{user_info}

SUJET: {prompt}

{article_info}

INSTRUCTIONS DE TON:
- Style: {tone_config['style']}
- Voix: {tone_config['voice']}
- Approche: {tone_config['approach']}

STRUCTURE LINKEDIN OBLIGATOIRE:
1. üéØ HOOK (1-2 lignes): Accroche qui arr√™te le scroll
2. üìù D√âVELOPPEMENT (3-4 paragraphes courts): 
   - Contexte ou histoire
   - Insight principal
   - Exemple concret ou donn√©es
   - Le√ßon/conseil actionnable
3. üí≠ ENGAGEMENT (1-2 lignes): Question directe qui invite aux commentaires
4. üè∑Ô∏è HASHTAGS (3-5): Pertinents et populaires

R√àGLES STRICTES:
‚úÖ Longueur: 800-1300 caract√®res maximum
‚úÖ Paragraphes de 1-2 lignes avec espaces entre eux
‚úÖ Utiliser des √©mojis strat√©giques (2-4 maximum)
‚úÖ √âviter le jargon, rester accessible
‚úÖ Inclure des chiffres ou statistiques si possible
‚úÖ Cr√©er de la valeur ajout√©e authentique
‚úÖ Finir par une question engageante
‚úÖ Hashtags pertinents pour {industry}

INTERDICTIONS:
‚ùå Pas de liens externes
‚ùå Pas de langage marketing agressif
‚ùå Pas de clich√©s LinkedIn
‚ùå Pas de promesses exag√©r√©es

Commencez directement par l'accroche, sans titre ni introduction.
"""
        
        return main_prompt
    
    def _simulate_linkedin_generation(
        self, 
        prompt: str, 
        tone: str, 
        industry: str,
        user_context: dict = None,
        article_context: dict = None
    ) -> str:
        """Mode simulation pour les tests et d√©veloppement"""
        logger.info(f"ü§ñ Simulation g√©n√©ration LinkedIn: {prompt[:50]}... (ton: {tone})")
        
        user_name = user_context.get('name', 'Expert') if user_context else 'Expert'
        
        if tone == "inspirant":
            return f"""üöÄ {prompt}

Hier, je r√©fl√©chissais √† cette question et voici ce qui m'a frapp√©...

Dans notre secteur {industry}, nous avons tendance √† nous concentrer sur la technique. Mais la vraie transformation vient de l'humain.

Mes 3 apprentissages cl√©s :
‚ú® L'innovation na√Æt de la curiosit√©, pas de la pression
ü§ù Les meilleures id√©es √©mergent des conversations inattendues  
üìà Le succ√®s se mesure √† l'impact, pas aux m√©triques

Et vous, quelle est votre vision pour transformer notre industrie ?

#Innovation #Leadership #{industry.capitalize()} #Transformation #Impact"""
        
        elif tone == "professionnel":
            return f"""üìä Analyse : {prompt}

D'apr√®s mon exp√©rience de 10 ans dans le {industry}, voici les enjeux critiques que nous devons adresser.

Les donn√©es montrent une √©volution majeure :
‚Ä¢ 78% des entreprises investissent dans cette direction
‚Ä¢ ROI moyen de +45% sur 18 mois
‚Ä¢ Transformation des processus existants n√©cessaire

La cl√© du succ√®s ? Une approche m√©thodique qui allie innovation et pragmatisme.

Quel est votre retour d'exp√©rience sur ce sujet ?

#Strat√©gie #Performance #{industry.capitalize()} #ROI #Innovation"""
        
        elif tone == "storytelling":
            return f"""üìñ {prompt}

Il y a 3 ans, j'ai v√©cu une situation qui a chang√© ma perspective...

Nous √©tions face √† un d√©fi majeur dans notre projet. L'√©quipe √©tait d√©courag√©e, les d√©lais serr√©s. 

C'est l√† que j'ai compris une v√©rit√© fondamentale : les obstacles ne sont pas des murs, mais des tremplins.

Le r√©sultat ? Non seulement nous avons livr√© √† temps, mais nous avons cr√©√© une solution qui d√©passe nos attentes initiales.

Avez-vous d√©j√† v√©cu un moment o√π l'√©chec s'est transform√© en opportunit√© ?

#R√©silience #Leadership #{industry.capitalize()} #SuccessStory #Apprentissage"""
        
        else:  # familier ou autre
            return f"""üí≠ {prompt}

Je me posais cette question ce matin en prenant mon caf√© ‚òï

Dans notre quotidien de {industry}, on oublie parfois l'essentiel :
üéØ Prendre du recul pour voir le big picture
ü§ù √âcouter vraiment ce que nous disent nos √©quipes
‚ö° Tester rapidement plut√¥t que de planifier √† l'infini

Parfois, les meilleures solutions viennent des conversations les plus simples.

Et vous, comment abordez-vous ce d√©fi au quotidien ?

#R√©flexion #Partage #{industry.capitalize()} #Quotidien #Simplicit√©"""
    
    def generate_hashtags(self, content: str, industry: str) -> list:
        """G√©n√©rer des hashtags pertinents pour un contenu"""
        if self.simulation_mode:
            return self._simulate_hashtags(content, industry)
        
        try:
            hashtag_prompt = f"""
Analysez ce contenu LinkedIn et g√©n√©rez 5-7 hashtags pertinents :

Contenu: {content[:200]}...
Secteur: {industry}

R√®gles:
- Hashtags populaires sur LinkedIn
- M√©lange de hashtags g√©n√©riques et sp√©cifiques au secteur
- √âviter les hashtags trop longs
- Privil√©gier l'engagement et la port√©e

Format: liste de hashtags s√©par√©s par des virgules, sans le #
"""
            response = self.model.generate_content(hashtag_prompt)
            hashtags = [f"#{tag.strip()}" for tag in response.text.strip().split(',')]
            return hashtags[:7]  # Limiter √† 7 hashtags
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration hashtags: {e}")
            return self._simulate_hashtags(content, industry)
    
    def _simulate_hashtags(self, content: str, industry: str) -> list:
        """Simulation de g√©n√©ration de hashtags"""
        base_tags = ['LinkedIn', 'Professionnel', 'Carriere', 'Leadership']
        
        industry_tags = {
            'tech': ['Tech', 'Innovation', 'IA', 'Numerique', 'Startups'],
            'marketing': ['Marketing', 'DigitalMarketing', 'Strategie', 'Croissance'],
            'finance': ['Finance', 'Investissement', 'Economie', 'Fintech'],
            'rh': ['RH', 'Recrutement', 'Talents', 'Management'],
            'consulting': ['Conseil', 'Strategie', 'Transformation', 'Performance']
        }
        
        specific_tags = industry_tags.get(industry, ['Business', 'Entreprise'])
        
        # Combiner et retourner
        all_tags = base_tags + specific_tags
        return [f"#{tag}" for tag in all_tags[:6]]
    
    def optimize_posting_time(self, industry: str, user_timezone: str = 'Europe/Paris') -> dict:
        """Sugg√©rer le meilleur moment pour publier"""
        # Simulation des meilleurs moments par industrie
        optimal_times = {
            'tech': {
                'days': ['tuesday', 'wednesday', 'thursday'],
                'hours': [9, 14, 17],
                'best': 'tuesday_09:00'
            },
            'marketing': {
                'days': ['monday', 'tuesday', 'wednesday'],
                'hours': [8, 13, 16],
                'best': 'tuesday_13:00'
            },
            'finance': {
                'days': ['tuesday', 'wednesday', 'thursday'],
                'hours': [8, 12, 15],
                'best': 'wednesday_08:00'
            },
            'default': {
                'days': ['tuesday', 'wednesday'],
                'hours': [9, 14],
                'best': 'tuesday_09:00'
            }
        }
        
        timing = optimal_times.get(industry, optimal_times['default'])
        
        return {
            'recommendedDays': timing['days'],
            'recommendedHours': timing['hours'],
            'bestTime': timing['best'],
            'timezone': user_timezone,
            'engagementBoost': '+34%',
            'reason': f'Bas√© sur l\'activit√© de votre audience {industry}'
        }
    
    def analyze_content_performance(self, content: str) -> dict:
        """Analyser le potentiel de performance d'un contenu"""
        # Simulation d'analyse de contenu
        score = 75  # Score par d√©faut
        
        # Facteurs d'engagement
        factors = {
            'hasQuestion': '?' in content,
            'hasEmojis': any(char in content for char in 'üöÄüí°üìà‚ú®üéØ'),
            'hasHashtags': '#' in content,
            'optimalLength': 800 <= len(content) <= 1300,
            'hasNumbers': any(char.isdigit() for char in content),
            'hasCallToAction': any(word in content.lower() for word in ['pensez', 'partagez', 'commentez', 'r√©agissez'])
        }
        
        # Calculer le score
        positive_factors = sum(factors.values())
        score = min(95, 60 + (positive_factors * 6))
        
        # Pr√©dictions
        estimated_reach = max(500, score * 50)
        estimated_engagement = max(20, int(estimated_reach * 0.05))
        
        return {
            'score': score,
            'level': 'High' if score >= 80 else 'Medium' if score >= 60 else 'Low',
            'estimatedReach': estimated_reach,
            'estimatedEngagement': estimated_engagement,
            'factors': factors,
            'suggestions': self._generate_suggestions(factors)
        }
    
    def _generate_suggestions(self, factors: dict) -> list:
        """G√©n√©rer des suggestions d'am√©lioration"""
        suggestions = []
        
        if not factors['hasQuestion']:
            suggestions.append("Ajoutez une question √† la fin pour encourager les commentaires")
        
        if not factors['hasEmojis']:
            suggestions.append("Utilisez 2-3 √©mojis pour rendre le post plus engageant")
        
        if not factors['hasHashtags']:
            suggestions.append("Ajoutez 3-5 hashtags pertinents pour am√©liorer la port√©e")
        
        if not factors['optimalLength']:
            suggestions.append("Ajustez la longueur entre 800-1300 caract√®res pour un engagement optimal")
        
        if not factors['hasNumbers']:
            suggestions.append("Incluez des chiffres ou statistiques pour plus de cr√©dibilit√©")
        
        return suggestions[:3]  # Limiter √† 3 suggestions
    
    def is_available(self) -> bool:
        """V√©rifier si le service Gemini est disponible"""
        return not self.simulation_mode
    
    def get_status(self) -> dict:
        """Obtenir le statut du service"""
        return {
            'service': 'Gemini AI',
            'available': self.is_available(),
            'simulation_mode': self.simulation_mode,
            'api_key_configured': bool(self.api_key),
            'model': 'gemini-1.5-pro' if self.model else None
        }
