import os
import logging
from typing import Dict, Any, Optional

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

logger = logging.getLogger(__name__)

class GeminiService:
    """Service pour la gÃ©nÃ©ration de contenu avec Google Gemini AI"""
    
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        
        if not self.api_key:
            logger.warning("GEMINI_API_KEY non trouvÃ©e, mode simulation activÃ©")
            self.simulation_mode = True
        elif not GEMINI_AVAILABLE:
            logger.warning("google-generativeai non installÃ©, mode simulation activÃ©")
            self.simulation_mode = True
        else:
            try:
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel("gemini-1.5-pro")
                self.simulation_mode = False
                logger.info("âœ… Gemini AI initialisÃ© avec succÃ¨s")
            except Exception as e:
                logger.error(f"âŒ Erreur initialisation Gemini: {e}")
                self.simulation_mode = True
    
    def generate_linkedin_post(
        self, 
        prompt: str, 
        tone: str = "professionnel", 
        industry: str = "general",
        user_context: dict = None,
        article_context: dict = None
    ) -> str:
        """
        GÃ©nÃ©rer un post LinkedIn optimisÃ©
        
        Args:
            prompt: Le sujet/prompt du post
            tone: Le ton souhaitÃ©
            industry: Le secteur d'activitÃ©
            user_context: Contexte utilisateur (nom, titre, etc.)
            article_context: Article source si applicable
            
        Returns:
            str: Le post gÃ©nÃ©rÃ©
        """
        if self.simulation_mode:
            return self._simulate_linkedin_generation(prompt, tone, industry, user_context, article_context)
        
        try:
            linkedin_prompt = self._build_linkedin_prompt(prompt, tone, industry, user_context, article_context)
            response = self.model.generate_content(linkedin_prompt)
            return response.text.strip()
        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration Gemini: {str(e)}")
            return self._simulate_linkedin_generation(prompt, tone, industry, user_context, article_context)
    
    def _build_linkedin_prompt(
        self, 
        prompt: str, 
        tone: str, 
        industry: str,
        user_context: dict = None,
        article_context: dict = None
    ) -> str:
        """Construire le prompt optimisÃ© pour LinkedIn"""
        
        # Instructions de ton
        tone_instructions = {
            "professionnel": {
                "style": "Adoptez un ton professionnel et expert, utilisez un vocabulaire prÃ©cis et crÃ©dible",
                "voice": "Position d'autoritÃ© dans votre domaine",
                "approach": "Analytique et factuel avec des insights pratiques"
            },
            "inspirant": {
                "style": "Soyez motivant et positif, encouragez l'action et le dÃ©passement",
                "voice": "Leader visionnaire qui inspire",
                "approach": "Optimiste avec une vision d'avenir"
            },
            "familier": {
                "style": "Utilisez un ton conversationnel et accessible, comme une discussion entre collÃ¨gues",
                "voice": "Approchable et authentique",
                "approach": "Personnel et relatable"
            },
            "expert": {
                "style": "DÃ©montrez votre expertise technique avec des dÃ©tails prÃ©cis",
                "voice": "AutoritÃ© reconnue dans le domaine",
                "approach": "Technique mais accessible"
            },
            "storytelling": {
                "style": "Racontez une histoire engageante avec des Ã©lÃ©ments narratifs",
                "voice": "Narrateur captivant",
                "approach": "Ã‰motionnel et mÃ©morable"
            }
        }
        
        tone_config = tone_instructions.get(tone, tone_instructions["professionnel"])
        
        # Contexte utilisateur
        user_info = ""
        if user_context:
            user_info = f"""
Contexte utilisateur:
- Nom: {user_context.get('name', 'Professionnel')}
- Secteur: {industry}
- Titre: {user_context.get('headline', f'Expert en {industry}')}
"""
        
        # Contexte article
        article_info = ""
        if article_context:
            article_info = f"""
Article source:
- Titre: {article_context.get('title', '')}
- Description: {article_context.get('description', '')}
- Source: {article_context.get('source', {}).get('name', '')}

Instructions: CrÃ©ez un post qui commente cet article avec votre expertise personnelle.
"""
        
        # Prompt principal
        main_prompt = f"""
Vous Ãªtes un expert en crÃ©ation de contenu LinkedIn. CrÃ©ez un post viral et engageant.

{user_info}

SUJET: {prompt}

{article_info}

INSTRUCTIONS DE TON:
- Style: {tone_config['style']}
- Voix: {tone_config['voice']}
- Approche: {tone_config['approach']}

STRUCTURE LINKEDIN OBLIGATOIRE:
1. ðŸŽ¯ HOOK (1-2 lignes): Accroche qui arrÃªte le scroll
2. ðŸ“ DÃ‰VELOPPEMENT (3-4 paragraphes courts): 
   - Contexte ou histoire
   - Insight principal
   - Exemple concret ou donnÃ©es
   - LeÃ§on/conseil actionnable
3. ðŸ’­ ENGAGEMENT (1-2 lignes): Question directe qui invite aux commentaires
4. ðŸ·ï¸ HASHTAGS (3-5): Pertinents et populaires

RÃˆGLES STRICTES:
âœ… Longueur: 800-1300 caractÃ¨res maximum
âœ… Paragraphes de 1-2 lignes avec espaces entre eux
âœ… Utiliser des Ã©mojis stratÃ©giques (2-4 maximum)
âœ… Ã‰viter le jargon, rester accessible
âœ… Inclure des chiffres ou statistiques si possible
âœ… CrÃ©er de la valeur ajoutÃ©e authentique
âœ… Finir par une question engageante
âœ… Hashtags pertinents pour {industry}

INTERDICTIONS:
âŒ Pas de liens externes
âŒ Pas de langage marketing agressif
âŒ Pas de clichÃ©s LinkedIn
âŒ Pas de promesses exagÃ©rÃ©es

Commencez directement par l'accroche, sans titre ni introduction.
"""
        
        return main_prompt
    
    def _simulate_linkedin_generation(
        self, 
        prompt: str, 
        tone: str, 
        industry: str,
        user_context: dict = None,
        article_context: dict = None
    ) -> str:
        """Mode simulation pour les tests et dÃ©veloppement"""
        logger.info(f"ðŸ¤– Simulation gÃ©nÃ©ration LinkedIn: {prompt[:50]}... (ton: {tone})")
        
        user_name = user_context.get('name', 'Expert') if user_context else 'Expert'
        
        if tone == "inspirant":
            return f"""ðŸš€ {prompt}

Hier, je rÃ©flÃ©chissais Ã  cette question et voici ce qui m'a frappÃ©...

Dans notre secteur {industry}, nous avons tendance Ã  nous concentrer sur la technique. Mais la vraie transformation vient de l'humain.

Mes 3 apprentissages clÃ©s :
âœ¨ L'innovation naÃ®t de la curiositÃ©, pas de la pression
ðŸ¤ Les meilleures idÃ©es Ã©mergent des conversations inattendues  
ðŸ“ˆ Le succÃ¨s se mesure Ã  l'impact, pas aux mÃ©triques

Et vous, quelle est votre vision pour transformer notre industrie ?

#Innovation #Leadership #{industry.capitalize()} #Transformation #Impact"""
        
        elif tone == "professionnel":
            return f"""ðŸ“Š Analyse : {prompt}

D'aprÃ¨s mon expÃ©rience de 10 ans dans le {industry}, voici les enjeux critiques que nous devons adresser.

Les donnÃ©es montrent une Ã©volution majeure :
â€¢ 78% des entreprises investissent dans cette direction
â€¢ ROI moyen de +45% sur 18 mois
â€¢ Transformation des processus existants nÃ©cessaire

La clÃ© du succÃ¨s ? Une approche mÃ©thodique qui allie innovation et pragmatisme.

Quel est votre retour d'expÃ©rience sur ce sujet ?

#StratÃ©gie #Performance #{industry.capitalize()} #ROI #Innovation"""
        
        elif tone == "storytelling":
            return f"""ðŸ“– {prompt}

Il y a 3 ans, j'ai vÃ©cu une situation qui a changÃ© ma perspective...

Nous Ã©tions face Ã  un dÃ©fi majeur dans notre projet. L'Ã©quipe Ã©tait dÃ©couragÃ©e, les dÃ©lais serrÃ©s. 

C'est lÃ  que j'ai compris une vÃ©ritÃ© fondamentale : les obstacles ne sont pas des murs, mais des tremplins.

Le rÃ©sultat ? Non seulement nous avons livrÃ© Ã  temps, mais nous avons crÃ©Ã© une solution qui dÃ©passe nos attentes initiales.

Avez-vous dÃ©jÃ  vÃ©cu un moment oÃ¹ l'Ã©chec s'est transformÃ© en opportunitÃ© ?

#RÃ©silience #Leadership #{industry.capitalize()} #SuccessStory #Apprentissage"""
        
        else:  # familier ou autre
            return f"""ðŸ’­ {prompt}

Je me posais cette question ce matin en prenant mon cafÃ© â˜•

Dans notre quotidien de {industry}, on oublie parfois l'essentiel :
ðŸŽ¯ Prendre du recul pour voir le big picture
ðŸ¤ Ã‰couter vraiment ce que nous disent nos Ã©quipes
âš¡ Tester rapidement plutÃ´t que de planifier Ã  l'infini

Parfois, les meilleures solutions viennent des conversations les plus simples.

Et vous, comment abordez-vous ce dÃ©fi au quotidien ?

#RÃ©flexion #Partage #{industry.capitalize()} #Quotidien #SimplicitÃ©"""
    
    def generate_hashtags(self, content: str, industry: str) -> list:
        """GÃ©nÃ©rer des hashtags pertinents pour un contenu"""
        if self.simulation_mode:
            return self._simulate_hashtags(content, industry)
        
        try:
            hashtag_prompt = f"""
Analysez ce contenu LinkedIn et gÃ©nÃ©rez 5-7 hashtags pertinents :

Contenu: {content[:200]}...
Secteur: {industry}

RÃ¨gles:
- Hashtags populaires sur LinkedIn
- MÃ©lange de hashtags gÃ©nÃ©riques et spÃ©cifiques au secteur
- Ã‰viter les hashtags trop longs
- PrivilÃ©gier l'engagement et la portÃ©e

Format: liste de hashtags sÃ©parÃ©s par des virgules, sans le #
"""
            response = self.model.generate_content(hashtag_prompt)
            hashtags = [f"#{tag.strip()}" for tag in response.text.strip().split(',')]
            return hashtags[:7]  # Limiter Ã  7 hashtags
        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration hashtags: {e}")
            return self._simulate_hashtags(content, industry)
    
    def _simulate_hashtags(self, content: str, industry: str) -> list:
        """Simulation de gÃ©nÃ©ration de hashtags"""
        base_tags = ['LinkedIn', 'Professionnel', 'Carriere', 'Leadership']
        
        industry_tags = {
            'tech': ['Tech', 'Innovation', 'IA', 'Numerique', 'Startups'],
            'marketing': ['Marketing', 'DigitalMarketing', 'Strategie', 'Croissance'],
            'finance': ['Finance', 'Investissement', 'Economie', 'Fintech'],
            'rh': ['RH', 'Recrutement', 'Talents', 'Management'],
            'consulting': ['Conseil', 'Strategie', 'Transformation', 'Performance']
        }
        
        specific_tags = industry_tags.get(industry, ['Business', 'Entreprise'])
        
        # Combiner et retourner
        all_tags = base_tags + specific_tags
        return [f"#{tag}" for tag in all_tags[:6]]
    
    def optimize_posting_time(self, industry: str, user_timezone: str = 'Europe/Paris') -> dict:
        """SuggÃ©rer le meilleur moment pour publier"""
        # Simulation des meilleurs moments par industrie
        optimal_times = {
            'tech': {
                'days': ['tuesday', 'wednesday', 'thursday'],
                'hours': [9, 14, 17],
                'best': 'tuesday_09:00'
            },
            'marketing': {
                'days': ['monday', 'tuesday', 'wednesday'],
                'hours': [8, 13, 16],
                'best': 'tuesday_13:00'
            },
            'finance': {
                'days': ['tuesday', 'wednesday', 'thursday'],
                'hours': [8, 12, 15],
                'best': 'wednesday_08:00'
            },
            'default': {
                'days': ['tuesday', 'wednesday'],
                'hours': [9, 14],
                'best': 'tuesday_09:00'
            }
        }
        
        timing = optimal_times.get(industry, optimal_times['default'])
        
        return {
            'recommendedDays': timing['days'],
            'recommendedHours': timing['hours'],
            'bestTime': timing['best'],
            'timezone': user_timezone,
            'engagementBoost': '+34%',
            'reason': f'BasÃ© sur l\'activitÃ© de votre audience {industry}'
        }
    
    def analyze_content_performance(self, content: str) -> dict:
        """Analyser le potentiel de performance d'un contenu"""
        # Simulation d'analyse de contenu
        score = 75  # Score par dÃ©faut
        
        # Facteurs d'engagement
        factors = {
            'hasQuestion': '?' in content,
            'hasEmojis': any(char in content for char in 'ðŸš€ðŸ’¡ðŸ“ˆâœ¨ðŸŽ¯'),
            'hasHashtags': '#' in content,
            'optimalLength': 800 <= len(content) <= 1300,
            'hasNumbers': any(char.isdigit() for char in content),
            'hasCallToAction': any(word in content.lower() for word in ['pensez', 'partagez', 'commentez', 'rÃ©agissez'])
        }
        
        # Calculer le score
        positive_factors = sum(factors.values())
        score = min(95, 60 + (positive_factors * 6))
        
        # PrÃ©dictions
        estimated_reach = max(500, score * 50)
        estimated_engagement = max(20, int(estimated_reach * 0.05))
        
        return {
            'score': score,
            'level': 'High' if score >= 80 else 'Medium' if score >= 60 else 'Low',
            'estimatedReach': estimated_reach,
            'estimatedEngagement': estimated_engagement,
            'factors': factors,
            'suggestions': self._generate_suggestions(factors)
        }
    
    def _generate_suggestions(self, factors: dict) -> list:
        """GÃ©nÃ©rer des suggestions d'amÃ©lioration"""
        suggestions = []
        
        if not factors['hasQuestion']:
            suggestions.append("Ajoutez une question Ã  la fin pour encourager les commentaires")
        
        if not factors['hasEmojis']:
            suggestions.append("Utilisez 2-3 Ã©mojis pour rendre le post plus engageant")
        
        if not factors['hasHashtags']:
            suggestions.append("Ajoutez 3-5 hashtags pertinents pour amÃ©liorer la portÃ©e")
        
        if not factors['optimalLength']:
            suggestions.append("Ajustez la longueur entre 800-1300 caractÃ¨res pour un engagement optimal")
        
        if not factors['hasNumbers']:
            suggestions.append("Incluez des chiffres ou statistiques pour plus de crÃ©dibilitÃ©")
        
        return suggestions[:3]  # Limiter Ã  3 suggestions
    
    def is_available(self) -> bool:
        """VÃ©rifier si le service Gemini est disponible"""
        return not self.simulation_mode
    
    def get_status(self) -> dict:
        """Obtenir le statut du service"""
        return {
            'service': 'Gemini AI',
            'available': self.is_available(),
            'simulation_mode': self.simulation_mode,
            'api_key_configured': bool(self.api_key),
            'model': 'gemini-1.5-pro' if self.model else None
        }
